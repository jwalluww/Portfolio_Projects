{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e1c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nHidden Markov Model (HMM) for Customer Journey Analysis\\n---\\n\\nüîç **Situation**:\\nCustomer journey data consists of observed actions like browsing,\\nemail engagement, and purchases, but the underlying behavioral states\\n(e.g., \"Exploring\" vs. \"Highly Engaged\") are unknown.\\nUnderstanding these hidden states could help businesses personalize marketing efforts and predict conversions.\\n\\nüìå **Task**:\\nI aimed to build a Hidden Markov Model (HMM) to infer hidden customer behavior states from observed actions.\\nThe goal was to segment users based on their engagement and predict their likelihood of purchasing or becoming inactive.\\n\\n‚ú® **Action**: \\n    Created Synthetic Customer Journey Data\\n        Simulated user interactions across five observed actions (browse, email engagement, app engagement, engaged browse, and purchase).\\n        Defined hidden states representing behavioral groups: Exploring, Engaged, Highly Engaged, Buyers, and Dormant.\\n        Modeled state transitions and observation probabilities based on realistic customer behavior.\\n    Preprocessed Data for HMM\\n        Encoded categorical actions into numerical values for model training.\\n        Organized sequences by user, ensuring correct formatting for HMM.\\n    Built & Trained the HMM Model\\n        Used a Multinomial HMM with different numbers of hidden states.\\n        Fit the model on user action sequences to learn hidden state transitions.\\n        Predicted the most likely hidden state sequence for each user.\\n    Evaluated Model Performance\\n        Compared models with 1-6 hidden states using Log-Likelihood, AIC, and BIC scores.\\n        Determined the optimal number of hidden states for best model fit.\\n\\nüìà **Result**:\\n    Successfully segmented users into inferred behavioral states based on engagement patterns.\\n    Identified key transition probabilities, such as how likely users were to progress from \"Exploring\" to \"Engaged\" or drop into \"Dormant.\"\\n    The best-fitting model suggested four distinct behavioral states, balancing complexity and interpretability.\\n    Businesses can use these insights to tailor interventions‚Äîe.g., targeting \"Highly Engaged\" users with discounts to push them toward a purchase.\\n\\nüöÄ **Next Steps**:\\n    Enhance Data Realism: Incorporate time-based factors, seasonal effects, or additional user attributes like demographics.\\n    Improve Model Complexity: Explore Hierarchical HMMs or Bayesian HMMs to add flexibility in state transitions.\\n    Predict Future Behavior: Use the trained HMM to forecast future customer actions and optimize marketing efforts.\\n    Deploy & Validate in Production: Apply the model to real customer data and measure its effectiveness in predicting conversions.\\n\\n‚úç **Author**: Justin Wall\\nüìÖ **Updated**: 03/12/2025\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inverse Probability Score Weighting\n",
    "---\n",
    "\n",
    "üîç **Situation**:\n",
    "\n",
    "\n",
    "üìå **Task**:\n",
    "\n",
    "\n",
    "‚ú® **Action**: \n",
    "\n",
    "\n",
    "üìà **Result**:\n",
    "\n",
    "\n",
    "üöÄ **Next Steps**:\n",
    "\n",
    "\n",
    "‚úç **Author**: Justin Wall\n",
    "üìÖ **Updated**: 04/05/2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73a09201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  purchase\n",
       "0        1.0         0\n",
       "1        1.0         0\n",
       "2        1.0         0\n",
       "3        1.0         0\n",
       "4        1.0         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate fake dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define total counts\n",
    "treated_count = 533_518\n",
    "control_count = 7_638_613\n",
    "\n",
    "# Generate treatment indicator (1 = saw ad, 0 = did not)\n",
    "treatment = np.concatenate([np.ones(treated_count), np.zeros(control_count)])\n",
    "\n",
    "# Generate purchases (based on given conversion rates)\n",
    "treated_purchases = np.random.choice([1, 0], size=treated_count, p=[4_393 / treated_count, 1 - (4_393 / treated_count)])\n",
    "control_purchases = np.random.choice([1, 0], size=control_count, p=[599 / control_count, 1 - (599 / control_count)])\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame({\n",
    "    \"treatment\": treatment,\n",
    "    \"purchase\": np.concatenate([treated_purchases, control_purchases])\n",
    "})\n",
    "\n",
    "# Check dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6aee671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(treatment\n",
       " 0.0    7638613\n",
       " 1.0     533518\n",
       " Name: count, dtype: int64,\n",
       " purchase\n",
       " 0    8167200\n",
       " 1       4931\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['treatment'].value_counts(), df['purchase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f3a88c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>purchase</th>\n",
       "      <th>past_purchases</th>\n",
       "      <th>site_visits</th>\n",
       "      <th>propensity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.065864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.065251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.065555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.065251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  purchase  past_purchases  site_visits  propensity_score\n",
       "0        1.0         0               1           10          0.065864\n",
       "1        1.0         0               0            5          0.065251\n",
       "2        1.0         0               1            6          0.065555\n",
       "3        1.0         0               0            5          0.065251\n",
       "4        1.0         0               0            3          0.065097"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate some synthetic user features (e.g., past behavior)\n",
    "df[\"past_purchases\"] = np.random.poisson(0.1, size=len(df))  # Simulating past purchases\n",
    "df[\"site_visits\"] = np.random.poisson(5, size=len(df))  # Simulating site visit frequency\n",
    "\n",
    "# Logistic regression to estimate propensity scores\n",
    "X = df[[\"past_purchases\", \"site_visits\"]]\n",
    "y = df[\"treatment\"]\n",
    "\n",
    "prop_model = LogisticRegression()\n",
    "prop_model.fit(X, y)\n",
    "\n",
    "# Get propensity scores (probability of treatment)\n",
    "df[\"propensity_score\"] = prop_model.predict_proba(X)[:, 1]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cee90c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>treatment</th>\n",
       "      <th>purchase</th>\n",
       "      <th>past_purchases</th>\n",
       "      <th>site_visits</th>\n",
       "      <th>propensity_score</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.065864</td>\n",
       "      <td>15.182761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.065251</td>\n",
       "      <td>15.325435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.065555</td>\n",
       "      <td>15.254434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.065251</td>\n",
       "      <td>15.325435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.065097</td>\n",
       "      <td>15.361586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   treatment  purchase  past_purchases  site_visits  propensity_score  \\\n",
       "0        1.0         0               1           10          0.065864   \n",
       "1        1.0         0               0            5          0.065251   \n",
       "2        1.0         0               1            6          0.065555   \n",
       "3        1.0         0               0            5          0.065251   \n",
       "4        1.0         0               0            3          0.065097   \n",
       "\n",
       "      weight  \n",
       "0  15.182761  \n",
       "1  15.325435  \n",
       "2  15.254434  \n",
       "3  15.325435  \n",
       "4  15.361586  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute inverse probability weights\n",
    "df[\"weight\"] = np.where(df[\"treatment\"] == 1, \n",
    "                        1 / df[\"propensity_score\"], \n",
    "                        1 / (1 - df[\"propensity_score\"]))\n",
    "\n",
    "# Check summary\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53b4d154",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\statsmodels\\base\\model.py:130: ValueWarning: unknown kwargs ['weights']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.003841\n",
      "         Iterations 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\statsmodels\\base\\model.py:130: ValueWarning: unknown kwargs ['weights']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:               purchase   No. Observations:              8172131\n",
      "Model:                          Logit   Df Residuals:                  8172129\n",
      "Method:                           MLE   Df Model:                            1\n",
      "Date:                Sat, 05 Apr 2025   Pseudo R-squ.:                  0.2433\n",
      "Time:                        06:14:29   Log-Likelihood:                -31391.\n",
      "converged:                       True   LL-Null:                       -41483.\n",
      "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -9.4668      0.041   -230.134      0.000      -9.547      -9.386\n",
      "treatment      4.6634      0.044    106.303      0.000       4.577       4.749\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.93 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n"
     ]
    }
   ],
   "source": [
    "# Fit weighted regression model\n",
    "model = smf.logit(\"purchase ~ treatment\", data=df, weights=df[\"weight\"]).fit()\n",
    "\n",
    "# Show results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3be7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
