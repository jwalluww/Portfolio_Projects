{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBayesian Network for Supply Chain Risk Mitigation using PGMPY\\n---\\n\\nðŸ” **Situation**:\\n- Simple Bayesian Network to estimate supply chain risk using PGMPY.\\n\\nðŸ“Œ **Task**:\\n- Directed Acyclic Graph (DAG) where nodes represent variables, and edges represent causal or probabilistic dependencies.\\n- Uses Conditional Probability Tables (CPTs) to define relationships.\\n- Ideal for causal modeling, decision support, and prediction.\\n- Use case fit: âœ… Best for supply chain risk estimation because disruptions often follow a causal chain (e.g., raw material shortages â†’ production delays â†’ supplier failure).\\n- PGMPY also supports Markov Networks but follow undirect graphs that do not have causal relationship - not as good for supply chain risk estimation.\\n\\nâœ¨ **Action**: \\n- We can make inferences about the probability of events in a supply chain given observed data. \\n\\nðŸ“ˆ **Result**:\\n- Extend the model to include more variables (e.g., transportation delays, natural disasters).\\n- More complex inferences (e.g., estimating the probability of multiple events occurring simultaneously).\\n\\nâœ **Author**: Justin Wall\\nðŸ“… **Updated**: 03/04/2025 \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bayesian Network for Supply Chain Risk Mitigation using PGMPY\n",
    "---\n",
    "\n",
    "ðŸ” **Situation**:\n",
    "- Simple Bayesian Network to estimate supply chain risk using PGMPY.\n",
    "\n",
    "ðŸ“Œ **Task**:\n",
    "- Directed Acyclic Graph (DAG) where nodes represent variables, and edges represent causal or probabilistic dependencies.\n",
    "- Uses Conditional Probability Tables (CPTs) to define relationships.\n",
    "- Ideal for causal modeling, decision support, and prediction.\n",
    "- Use case fit: âœ… Best for supply chain risk estimation because disruptions often follow a causal chain (e.g., raw material shortages â†’ production delays â†’ supplier failure).\n",
    "- PGMPY also supports Markov Networks but follow undirect graphs that do not have causal relationship - not as good for supply chain risk estimation.\n",
    "\n",
    "âœ¨ **Action**: \n",
    "- We can make inferences about the probability of events in a supply chain given observed data. \n",
    "\n",
    "ðŸ“ˆ **Result**:\n",
    "- Extend the model to include more variables (e.g., transportation delays, natural disasters).\n",
    "- More complex inferences (e.g., estimating the probability of multiple events occurring simultaneously).\n",
    "\n",
    "âœ **Author**: Justin Wall\n",
    "ðŸ“… **Updated**: 03/04/2025 \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================\n",
    "# Create Fake Dataset for Supply Chain Risk\n",
    "# =============================================\n",
    "#%%\n",
    "import bnlearn as bn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Supplier_Delay Inventory_Level Production_Delay Demand_Surge Customer_Delay\n",
      "0             No             Low               No           No             No\n",
      "1             No          Medium              Yes           No             No\n",
      "2             No            High               No           No             No\n",
      "3             No          Medium              Yes           No            Yes\n",
      "4            Yes            High               No           No            Yes\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Generate Dataset for Supply Chain Risk\n",
    "# =============================================\n",
    "#%%\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate synthetic categorical data for supply chain risk\n",
    "data = pd.DataFrame({\n",
    "    \"Supplier_Delay\": np.random.choice([\"Yes\", \"No\"], size=1000, p=[0.2, 0.8]),\n",
    "    \"Inventory_Level\": np.random.choice([\"Low\", \"Medium\", \"High\"], size=1000, p=[0.3, 0.5, 0.2]),\n",
    "    \"Production_Delay\": np.random.choice([\"Yes\", \"No\"], size=1000, p=[0.25, 0.75]),\n",
    "    \"Demand_Surge\": np.random.choice([\"Yes\", \"No\"], size=1000, p=[0.15, 0.85]),\n",
    "    \"Customer_Delay\": np.random.choice([\"Yes\", \"No\"], size=1000, p=[0.3, 0.7])\n",
    "})\n",
    "\n",
    "# Show first 5 rows\n",
    "print(data.head())\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Computing best DAG using [hc]\n",
      "[bnlearn] >Set scoring type at [bic]\n",
      "[bnlearn] >Compute structure scores for model comparison (higher is better).\n",
      "{'model': <pgmpy.base.DAG.DAG object at 0x000001FC73AABC50>, 'model_edges': [], 'adjmat': target            Supplier_Delay  Inventory_Level  Production_Delay  \\\n",
      "source                                                                \n",
      "Supplier_Delay             False            False             False   \n",
      "Inventory_Level            False            False             False   \n",
      "Production_Delay           False            False             False   \n",
      "Demand_Surge               False            False             False   \n",
      "Customer_Delay             False            False             False   \n",
      "\n",
      "target            Demand_Surge  Customer_Delay  \n",
      "source                                          \n",
      "Supplier_Delay           False           False  \n",
      "Inventory_Level          False           False  \n",
      "Production_Delay         False           False  \n",
      "Demand_Surge             False           False  \n",
      "Customer_Delay           False           False  , 'config': {'method': 'hc', 'scoring': 'bic', 'black_list': None, 'white_list': None, 'bw_list_method': None, 'max_indegree': None, 'tabu_length': 100, 'epsilon': 0.0001, 'max_iter': 1000000.0, 'root_node': None, 'class_node': None, 'fixed_edges': set(), 'return_all_dags': False, 'n_jobs': -1, 'verbose': 3}, 'structure_scores': {'k2': -3157.877418240543, 'bic': -3158.776972088292, 'bdeu': -3159.576752554105, 'bds': -3166.5082243597044}}\n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Build the Model\n",
    "# =============================================\n",
    "#%%\n",
    "# Learn the structure using bnlearn\n",
    "model = bn.structure_learning.fit(data, methodtype='hc', scoretype='bic')\n",
    "\n",
    "# Print the learned structure\n",
    "print(model)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn]> Nothing to plot because no edges are present between nodes. \n"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Visualize the DAG\n",
    "# =============================================\n",
    "#%%\n",
    "bn.plot(model)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bnlearn] >Parameter learning> Computing parameters using [bayes]\n",
      "[bnlearn] >Compute structure scores for model comparison (higher is better).\n",
      "[bnlearn] >WARNING> Skipping computing structure score for [k2].\n",
      "[bnlearn] >Variable Elimination.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Node Supplier_Delay not in not in graph",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m bn\u001b[38;5;241m.\u001b[39mparameter_learning\u001b[38;5;241m.\u001b[39mfit(model, data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Perform inference: What is the probability of Customer_Delay given Supplier_Delay = Yes?\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mbn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCustomer_Delay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSupplier_Delay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(query)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m#%%\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\bnlearn\\inference.py:105\u001b[0m, in \u001b[0;36mfit\u001b[1;34m(model, variables, evidence, to_df, elimination_order, joint, groupby, verbose)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[bnlearn] >Error: Input model does not contain learned CPDs. hint: did you run parameter_learning.fit()?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Computing the probability P(class | evidence)\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_infer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevidence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melimination_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43melimination_order\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Store also in dataframe\u001b[39;00m\n\u001b[0;32m    107\u001b[0m query\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m bnlearn\u001b[38;5;241m.\u001b[39mquery2df(query, variables\u001b[38;5;241m=\u001b[39mvariables, groupby\u001b[38;5;241m=\u001b[39mgroupby, verbose\u001b[38;5;241m=\u001b[39mverbose) \u001b[38;5;28;01mif\u001b[39;00m to_df \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pgmpy\\inference\\ExactInference.py:318\u001b[0m, in \u001b[0;36mVariableElimination.query\u001b[1;34m(self, variables, evidence, virtual_evidence, elimination_order, joint, show_progress)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# Step 3: Prune the network based on variables and evidence.\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, BayesianNetwork):\n\u001b[1;32m--> 318\u001b[0m     model_reduced, evidence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prune_bayesian_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    319\u001b[0m     factors \u001b[38;5;241m=\u001b[39m model_reduced\u001b[38;5;241m.\u001b[39mcpds\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pgmpy\\inference\\base.py:153\u001b[0m, in \u001b[0;36mInference._prune_bayesian_model\u001b[1;34m(self, variables, evidence)\u001b[0m\n\u001b[0;32m    149\u001b[0m variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mnodes()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(variables) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(variables)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;66;03m# Step 1: Remove all the variables that are d-separated from `variables` when conditioned\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;66;03m#         on `evidence`\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactive_trail_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevidence\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_latents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m    155\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    156\u001b[0m d_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m\u001b[38;5;241m.\u001b[39munion(\u001b[38;5;241m*\u001b[39md_connected\u001b[38;5;241m.\u001b[39mvalues())\u001b[38;5;241m.\u001b[39munion(evidence\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m    157\u001b[0m bn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msubgraph(d_connected)\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pgmpy\\base\\DAG.py:719\u001b[0m, in \u001b[0;36mDAG.active_trail_nodes\u001b[1;34m(self, variables, observed, include_latents)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    718\u001b[0m     observed_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 719\u001b[0m ancestors_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ancestors_of\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobserved_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;66;03m# Direction of flow of information\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;66;03m# up ->  from parent to child\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;66;03m# down -> from child to parent\u001b[39;00m\n\u001b[0;32m    725\u001b[0m active_trails \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pgmpy\\base\\DAG.py:781\u001b[0m, in \u001b[0;36mDAG._get_ancestors_of\u001b[1;34m(self, nodes)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodes():\n\u001b[1;32m--> 781\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNode \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in not in graph\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    783\u001b[0m ancestors_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m    784\u001b[0m nodes_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(nodes)\n",
      "\u001b[1;31mValueError\u001b[0m: Node Supplier_Delay not in not in graph"
     ]
    }
   ],
   "source": [
    "# =============================================\n",
    "# Perform Model Inference\n",
    "# =============================================\n",
    "#%%\n",
    "# Learn parameters\n",
    "model = bn.parameter_learning.fit(model, data)\n",
    "\n",
    "# Perform inference: What is the probability of Customer_Delay given Supplier_Delay = Yes?\n",
    "query = bn.inference.fit(model, variables=[\"Customer_Delay\"], evidence={\"Supplier_Delay\": \"Yes\"})\n",
    "print(query)\n",
    "#%%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
