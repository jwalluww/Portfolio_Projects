{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b5349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "SHAP Interaction Values using \n",
    "\n",
    "From: Maya Thompson (City Mobility Manager)\n",
    "To: Data Science Team\n",
    "Subject: Understanding Bike-Share Demand Drivers\n",
    "\n",
    "Hi Justin,\n",
    "\n",
    "We‚Äôve been looking at our bike-share ridership numbers and while we have some ideas about what drives\n",
    "\n",
    "demand (like weather, time of day, and weekends), the team keeps running into confusing situations where things don‚Äôt add up.\n",
    "\n",
    "On hot weekends, demand seems to spike ‚Äî but not on hot weekdays.\n",
    "\n",
    "Surge pricing seems to help sometimes, but not always.\n",
    "\n",
    "Riders complain that even a small chance of rain kills demand, especially in humid weather.\n",
    "\n",
    "Right now, our marketing and ops teams don‚Äôt know which combinations of factors matter most.\n",
    "\n",
    "Could you build a quick analysis to show us not just the individual effects of these features,\n",
    "\n",
    "but also how they interact with each other?\n",
    "\n",
    "Ideally, we‚Äôd like some visuals we can share in our next planning meeting that\n",
    "\n",
    "highlight the strongest pairs of features influencing ridership.\n",
    "\n",
    "Thanks so much,\n",
    "Maya\n",
    "\n",
    "‚úç **Author**: Justin Wall\n",
    "üìÖ **Date**: 02/13/2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29564056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wallj\\AppData\\Local\\Temp\\ipykernel_31268\\989824901.py:15: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  timestamps = pd.date_range(start, periods=n, freq=\"H\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>rides</th>\n",
       "      <th>temp_F</th>\n",
       "      <th>humidity_pct</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>rain_prob</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>near_park</th>\n",
       "      <th>surge_pricing_on</th>\n",
       "      <th>holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-06-01 00:00:00</td>\n",
       "      <td>84</td>\n",
       "      <td>82.1</td>\n",
       "      <td>82</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-06-01 01:00:00</td>\n",
       "      <td>95</td>\n",
       "      <td>80.7</td>\n",
       "      <td>88</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-06-01 02:00:00</td>\n",
       "      <td>80</td>\n",
       "      <td>74.1</td>\n",
       "      <td>59</td>\n",
       "      <td>16.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-06-01 03:00:00</td>\n",
       "      <td>60</td>\n",
       "      <td>73.8</td>\n",
       "      <td>71</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-06-01 04:00:00</td>\n",
       "      <td>92</td>\n",
       "      <td>70.9</td>\n",
       "      <td>56</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp  rides  temp_F  humidity_pct  wind_mph  rain_prob  \\\n",
       "0 2024-06-01 00:00:00     84    82.1            82      12.5        0.0   \n",
       "1 2024-06-01 01:00:00     95    80.7            88       8.1        0.0   \n",
       "2 2024-06-01 02:00:00     80    74.1            59      16.6        0.0   \n",
       "3 2024-06-01 03:00:00     60    73.8            71       4.0        0.0   \n",
       "4 2024-06-01 04:00:00     92    70.9            56       4.3        0.0   \n",
       "\n",
       "   is_weekend  hour_of_day  near_park  surge_pricing_on  holiday  \n",
       "0           1            0          1                 0        0  \n",
       "1           1            1          1                 0        0  \n",
       "2           1            2          1                 1        0  \n",
       "3           1            3          1                 0        0  \n",
       "4           1            4          1                 0        0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ================================= #\n",
    "# Generate Fake Bike Share Data     #\n",
    "# ================================= #\n",
    "#%%\n",
    "# Regenerate with a small fix (use np.clip instead of ndarray.clip to avoid Index edge-cases)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "n_days = 50\n",
    "hours_per_day = 24\n",
    "n = n_days * hours_per_day\n",
    "start = pd.Timestamp(\"2024-06-01\")\n",
    "\n",
    "timestamps = pd.date_range(start, periods=n, freq=\"H\")\n",
    "hour_of_day = timestamps.hour\n",
    "day_of_week = timestamps.dayofweek\n",
    "is_weekend = ((day_of_week >= 5).astype(int))\n",
    "\n",
    "daily_base = rng.normal(72, 8, size=n_days)\n",
    "diurnal = 10 * np.sin(2 * np.pi * (hour_of_day - 15) / 24)\n",
    "temp_F = np.repeat(daily_base, hours_per_day) + diurnal + rng.normal(0, 2.0, n)\n",
    "temp_F = np.clip(temp_F, 35, 98)\n",
    "\n",
    "humidity_base = rng.normal(60, 12, size=n) + 10 * np.cos(2 * np.pi * (hour_of_day) / 24)\n",
    "humidity_base = np.clip(humidity_base, 20, 100)\n",
    "\n",
    "rain_events = rng.binomial(1, 0.15, size=n_days)\n",
    "rain_prob = np.repeat(rain_events, hours_per_day) * rng.beta(2, 5, size=n)\n",
    "rain_prob = np.maximum(rain_prob, rng.binomial(1, 0.03, size=n) * rng.uniform(0.1, 0.6, size=n))\n",
    "\n",
    "wind_mph = np.clip(rng.gamma(3, 2, size=n), 0, 30)\n",
    "\n",
    "base_surge = (hour_of_day >= 17).astype(int) * rng.binomial(1, 0.4, size=n)\n",
    "weekend_surge = is_weekend * rng.binomial(1, 0.30, size=n)\n",
    "surge_pricing_on = np.clip(base_surge + weekend_surge, 0, 1)\n",
    "\n",
    "holiday_days = rng.choice(np.arange(n_days), size=max(1, int(0.05 * n_days)), replace=False)\n",
    "holiday = np.isin(np.repeat(np.arange(n_days), hours_per_day), holiday_days).astype(int)\n",
    "\n",
    "near_park = np.ones(n, dtype=int)\n",
    "\n",
    "humidity_pct = np.clip(humidity_base + 35 * (rain_prob > 0.4), 20, 100)\n",
    "\n",
    "commute_wave = (\n",
    "    18 * np.exp(-0.5 * ((hour_of_day - 8) / 2.5) ** 2) +\n",
    "    28 * np.exp(-0.5 * ((hour_of_day - 18) / 3.0) ** 2)\n",
    ")\n",
    "\n",
    "beta_temp = 0.9 * np.maximum(temp_F - 50, 0)\n",
    "beta_humidity = -0.08 * (humidity_pct - 60)\n",
    "beta_wind = -0.7 * np.maximum(wind_mph - 8, 0)\n",
    "beta_rain = -40 * rain_prob\n",
    "beta_weekend = 10 * is_weekend\n",
    "beta_surge = 6 * surge_pricing_on\n",
    "beta_holiday = -8 * holiday\n",
    "\n",
    "interaction_temp_weekend = 0.45 * (temp_F - 55) * is_weekend\n",
    "interaction_surge_evening = 12 * surge_pricing_on * (hour_of_day >= 17)\n",
    "interaction_rain_humid = -25 * rain_prob * np.clip((humidity_pct - 60) / 40, 0, 1)\n",
    "interaction_wind_cold = -0.9 * wind_mph * (np.clip(60 - temp_F, 0, 20) / 20)\n",
    "\n",
    "mu = (\n",
    "    35 + commute_wave\n",
    "    + beta_temp + beta_humidity + beta_wind + beta_rain + beta_weekend + beta_surge + beta_holiday\n",
    "    + interaction_temp_weekend + interaction_surge_evening + interaction_rain_humid + interaction_wind_cold\n",
    ")\n",
    "\n",
    "epsilon = rng.normal(0, 6, size=n)\n",
    "rides = np.clip(np.round(mu + epsilon), 0, None).astype(int)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"timestamp\": timestamps,\n",
    "    \"rides\": rides,\n",
    "    \"temp_F\": np.round(temp_F, 1),\n",
    "    \"humidity_pct\": np.round(humidity_pct, 0).astype(int),\n",
    "    \"wind_mph\": np.round(wind_mph, 1),\n",
    "    \"rain_prob\": np.round(rain_prob, 3),\n",
    "    \"is_weekend\": is_weekend,\n",
    "    \"hour_of_day\": hour_of_day,\n",
    "    \"near_park\": near_park,\n",
    "    \"surge_pricing_on\": surge_pricing_on,\n",
    "    \"holiday\": holiday\n",
    "})\n",
    "\n",
    "# path = \"/mnt/data/bike_share_hourly.csv\"\n",
    "# df.to_csv(path, index=False)\n",
    "\n",
    "# import caas_jupyter_tools as cj\n",
    "# cj.display_dataframe_to_user(\"Bike-share synthetic dataset (hourly)\", df.head(25))\n",
    "\n",
    "# path\n",
    "\n",
    "df.head()\n",
    "\n",
    "#%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca86836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows, Cols: (1200, 11)\n",
      "            timestamp  rides  temp_F  humidity_pct  wind_mph  rain_prob  \\\n",
      "0 2024-06-01 00:00:00     84    82.1            82      12.5        0.0   \n",
      "1 2024-06-01 01:00:00     95    80.7            88       8.1        0.0   \n",
      "2 2024-06-01 02:00:00     80    74.1            59      16.6        0.0   \n",
      "3 2024-06-01 03:00:00     60    73.8            71       4.0        0.0   \n",
      "4 2024-06-01 04:00:00     92    70.9            56       4.3        0.0   \n",
      "\n",
      "   is_weekend  hour_of_day  near_park  surge_pricing_on  holiday  \n",
      "0           1            0          1                 0        0  \n",
      "1           1            1          1                 0        0  \n",
      "2           1            2          1                 1        0  \n",
      "3           1            3          1                 0        0  \n",
      "4           1            4          1                 0        0  \n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 1) SETUP & LOAD DATA\n",
    "# =============================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "import shap\n",
    "\n",
    "# df = pd.read_csv(\"/mnt/data/bike_share_hourly.csv\", parse_dates=[\"timestamp\"])\n",
    "print(\"Rows, Cols:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "092fe187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (960, 9)  Test: (240, 9)\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 2) FEATURE PREP & TRAIN/TEST SPLIT\n",
    "# -----------------------------\n",
    "# What: Select features, split into train and test.\n",
    "# Why: Keep modeling honest and allow quick RMSE check.\n",
    "# =============================\n",
    "target = \"rides\"\n",
    "features = [\"temp_F\",\n",
    "            \"humidity_pct\",\n",
    "            \"wind_mph\",\n",
    "            \"rain_prob\",\n",
    "            \"is_weekend\",\n",
    "            \"hour_of_day\",\n",
    "            \"near_park\",\n",
    "            \"surge_pricing_on\",\n",
    "            \"holiday\"]\n",
    "\n",
    "X = df[features].copy()\n",
    "y = df[target].values\n",
    "\n",
    "# Train/test split (time-aware optional; here we do a random split for simplicity)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4456de97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 50.75\n"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 3) TRAIN A COMPACT TREE MODEL (XGBoost)\n",
    "# -----------------------------\n",
    "# What: Fit a small, readable XGBoost regressor.\n",
    "# Why: Tree ensembles naturally capture interactions; SHAP has exact interaction values for trees.\n",
    "# =============================\n",
    "model = XGBRegressor(\n",
    "    n_estimators=350,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42,\n",
    "    n_jobs=4\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Quick performance check\n",
    "preds_test = model.predict(X_test)\n",
    "rmse = mean_squared_error(y_test, preds_test)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c937f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=0.9, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.08, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=4, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=350, n_jobs=4,\n",
      "             num_parallel_tree=None, random_state=42, ...)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e6c4840",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 695: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     np\u001b[38;5;241m.\u001b[39mint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Reuse existing trained `model`, `X`\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m explainer \u001b[38;5;241m=\u001b[39m \u001b[43mshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTreeExplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# # Subsample for speed\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# rng = np.random.RandomState(0)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# sample_idx = rng.choice(len(X), size=min(800, len(X)), replace=False)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# print(\"X_shap shape:\", X_shap.shape)\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# print(\"interaction_values shape:\", np.array(interaction_values).shape)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\shap\\explainers\\_tree.py:166\u001b[0m, in \u001b[0;36mTreeExplainer.__init__\u001b[1;34m(self, model, data, model_output, feature_perturbation, feature_names, approximate, **deprecated_options)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_perturbation \u001b[38;5;241m=\u001b[39m feature_perturbation\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpected_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mTreeEnsemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_output \u001b[38;5;241m=\u001b[39m model_output\n\u001b[0;32m    168\u001b[0m \u001b[38;5;66;03m#self.model_output = self.model.model_output # this allows the TreeEnsemble to translate model outputs types by how it loads the model\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\shap\\explainers\\_tree.py:997\u001b[0m, in \u001b[0;36mTreeEnsemble.__init__\u001b[1;34m(self, model, data, data_missing, model_output)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moriginal_model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mget_booster()\n\u001b[0;32m    996\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 997\u001b[0m xgb_loader \u001b[38;5;241m=\u001b[39m \u001b[43mXGBTreeModelLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moriginal_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrees \u001b[38;5;241m=\u001b[39m xgb_loader\u001b[38;5;241m.\u001b[39mget_trees(data\u001b[38;5;241m=\u001b[39mdata, data_missing\u001b[38;5;241m=\u001b[39mdata_missing)\n\u001b[0;32m    999\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_offset \u001b[38;5;241m=\u001b[39m xgb_loader\u001b[38;5;241m.\u001b[39mbase_score\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\shap\\explainers\\_tree.py:1687\u001b[0m, in \u001b[0;36mXGBTreeModelLoader.__init__\u001b[1;34m(self, xgb_model)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_arr(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m29\u001b[39m) \u001b[38;5;66;03m# reserved\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_obj_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname_obj_len\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_gbm_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1689\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_gbm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_gbm_len)\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\shap\\explainers\\_tree.py:1808\u001b[0m, in \u001b[0;36mXGBTreeModelLoader.read_str\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_str\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[1;32m-> 1808\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m size\n\u001b[0;32m   1810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m val\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 695: invalid start byte"
     ]
    }
   ],
   "source": [
    "# =============================\n",
    "# 4) SHAP EXPLAINER & INTERACTION VALUES\n",
    "# -----------------------------\n",
    "# What: Build a SHAP TreeExplainer, compute SHAP values and SHAP interaction values.\n",
    "# Why: Interaction values reveal how PAIRS of features push predictions up/down together.\n",
    "# =============================\n",
    "# Compatibility patch for SHAP expecting deprecated numpy types\n",
    "if not hasattr(np, \"int\"):\n",
    "    np.int = int\n",
    "\n",
    "# Reuse existing trained `model`, `X`\n",
    "explainer = shap.TreeExplainer(model)\n",
    "\n",
    "# # Subsample for speed\n",
    "# rng = np.random.RandomState(0)\n",
    "# sample_idx = rng.choice(len(X), size=min(800, len(X)), replace=False)\n",
    "# X_shap = X.iloc[sample_idx]\n",
    "\n",
    "# # Compute SHAP and interaction values\n",
    "# shap_values = explainer.shap_values(X_shap)\n",
    "# interaction_values = explainer.shap_interaction_values(X_shap)\n",
    "\n",
    "# print(\"X_shap shape:\", X_shap.shape)\n",
    "# print(\"interaction_values shape:\", np.array(interaction_values).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2099256c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
