{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uplift Models using EconML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Goal: Predict the people most likely to click on a display ad given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For saving models\n",
    "import joblib\n",
    "\n",
    "# EconML Libraries\n",
    "from econml.metalearners import SLearner, TLearner, XLearner\n",
    "from econml.policy import PolicyTree\n",
    "\n",
    "# Dataset\n",
    "from sklift.datasets import fetch_criteo\n",
    "\n",
    "# Scikit-learn Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, roc_auc_score\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# random state\n",
    "rs = 481516234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "# dataset = fetch_criteo(target_col='conversion', treatment_col='exposure')\n",
    "# data, target, treatment = dataset.data, dataset.target, dataset.treatment\n",
    "\n",
    "# alternative option\n",
    "data, target, treatment = fetch_criteo(target_col='conversion', treatment_col='exposure', return_X_y_t=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13979592 entries, 0 to 13979591\n",
      "Data columns (total 12 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   f0      float64\n",
      " 1   f1      float64\n",
      " 2   f2      float64\n",
      " 3   f3      float64\n",
      " 4   f4      float64\n",
      " 5   f5      float64\n",
      " 6   f6      float64\n",
      " 7   f7      float64\n",
      " 8   f8      float64\n",
      " 9   f9      float64\n",
      " 10  f10     float64\n",
      " 11  f11     float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 1.2 GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 13979592 entries, 0 to 13979591\n",
      "Series name: conversion\n",
      "Non-Null Count     Dtype\n",
      "--------------     -----\n",
      "13979592 non-null  Int8 \n",
      "dtypes: Int8(1)\n",
      "memory usage: 26.7 MB\n"
     ]
    }
   ],
   "source": [
    "target.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conversion\n",
       "0    13938818\n",
       "1       40774\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exposure\n",
       "0    13551380\n",
       "1      428212\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treatment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and test sets\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test = train_test_split(data,target,treatment, test_size=0.3, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### S-Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://econml.azurewebsites.net/_autosummary/econml.metalearners.SLearner.html\n",
    "- The S-Learner in EconML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 58min 40s\n",
      "Wall time: 2h 22s\n"
     ]
    }
   ],
   "source": [
    "# S-learner\n",
    "s_learner = SLearner(overall_model=RandomForestRegressor(random_state=rs))\n",
    "s_learner.fit(Y_train, T_train, X=X_train)\n",
    "\n",
    "# Predict treatment effects\n",
    "s_te = s_learner.effect(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump out predictions\n",
    "df_s_te = pd.DataFrame(s_te, columns=['s_te'])\n",
    "df_s_te.to_csv('s_te.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s_learner_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the SLearner model to a file\n",
    "joblib.dump(s_learner, 's_learner_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SLearner model from the file\n",
    "s_learner = joblib.load('s_learner_model.pkl')\n",
    "\n",
    "# You can now use the loaded model\n",
    "s_te = s_learner.effect(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treatment Effect Estimation\n",
    "- The `effect` method calculates the Conditional Average Treatment Effect (CATE) for each observation. This provides an overall understanding of the treatment effect distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Treatment Effect: 0.49414088911998494\n"
     ]
    }
   ],
   "source": [
    "# Example: Evaluate mean predicted treatment effect\n",
    "print(f\"Mean Treatment Effect: {np.mean(s_te)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal Model Inference\n",
    "- `EconML` allows you to calculate confidence intervals and p-values for treatment effect estimates. This is especially useful for determining the statistical significance of the effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't call 'effect_interval' because 'inference' is None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate treatment effects with confidence intervals\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m predicted_effects, lower_bound, upper_bound \u001b[38;5;241m=\u001b[39m \u001b[43ms_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meffect_interval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Example: Display treatment effects with intervals\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted Effects: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_effects[:\u001b[38;5;241m5\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\econml\\_cate_estimator.py:338\u001b[0m, in \u001b[0;36mBaseCateEstimator._defer_to_inference.<locals>.call\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m args \u001b[38;5;241m=\u001b[39m bound_args\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# remove self\u001b[39;00m\n\u001b[0;32m    337\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m bound_args\u001b[38;5;241m.\u001b[39mkwargs\n\u001b[1;32m--> 338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_use_inference_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wallj\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\econml\\_cate_estimator.py:328\u001b[0m, in \u001b[0;36mBaseCateEstimator._use_inference_method\u001b[1;34m(self, name, *args, **kwargs)\u001b[0m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference, name)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 328\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m because \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minference\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is None\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m name)\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't call 'effect_interval' because 'inference' is None"
     ]
    }
   ],
   "source": [
    "# Calculate treatment effects with confidence intervals\n",
    "predicted_effects, lower_bound, upper_bound = s_learner.effect_interval(X_test, alpha=0.05)\n",
    "\n",
    "# Example: Display treatment effects with intervals\n",
    "print(f\"Predicted Effects: {predicted_effects[:5]}\")\n",
    "print(f\"95% CI Lower Bound: {lower_bound[:5]}\")\n",
    "print(f\"95% CI Upper Bound: {upper_bound[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Evaluation\n",
    "- `EconML` supports policy evaluation through policy trees and other methods, which help determine how a treatment policy would perform based on predicted effects. This is particularly useful for binary treatment variables to decide who should receive the treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PolicyTree.fit() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Fit a policy tree based on treatment effects\u001b[39;00m\n\u001b[0;32m      2\u001b[0m policy_tree \u001b[38;5;241m=\u001b[39m PolicyTree()\n\u001b[1;32m----> 3\u001b[0m \u001b[43mpolicy_tree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Visualize the policy tree\u001b[39;00m\n\u001b[0;32m      6\u001b[0m policy_tree\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mTypeError\u001b[0m: PolicyTree.fit() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "# Fit a policy tree based on treatment effects\n",
    "policy_tree = PolicyTree()\n",
    "policy_tree.fit(X_test, T_test, Y_test)\n",
    "\n",
    "# Visualize the policy tree\n",
    "policy_tree.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.28602605214927895\n"
     ]
    }
   ],
   "source": [
    "# AUC Score (if ground-truth treatment effect is available)\n",
    "auc_score = roc_auc_score(T_test, s_te)\n",
    "print(f\"AUC Score: {auc_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Treatment Effect (ITE) Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSE between true and predicted treatment effects\n",
    "true_effects = some_ground_truth_function(X_test)\n",
    "rmse = mean_squared_error(true_effects, predicted_effects, squared=False)\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
